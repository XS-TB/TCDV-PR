# -*- coding: utf-8 -*-
"""PR2Tipologia_XavierSancho-Tello_LauraGandia.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fj6wq_OKsWpuItcnH-3lPxFuApF3eclZ

# Pràctica 2 Tipologia i cicle de vida de les dades: Codi Python
Xavier Sancho-Tello Bayarri i Laura Gandia Barlocci
"""

#Prèvia: instal·lació llibreries
#REPASSAR
#!pip install requests
#!pip install beautifulsoup4
#!pip install selenium
#!pip install python-whois
#!pip install builtwith
#!apt update #assegurar-nos que està actualitzat
#!apt install chromium-chromedriver #instalem un chrome driver
#!pip install selenium #instalem selenium per a gestionar el contingut dinàmic
#!pip install python-dateutil

# connectem amb google drive
from google.colab import drive
drive.mount('/content/drive')

# set wd
import os
#%cp '/content/drive/MyDrive/Colab_Notebooks'
os.chdir('/content/drive/MyDrive/Colab_Notebooks')

# set wd xavi
import os
#%cp '/content/drive/MyDrive/Colab_Notebooks'
os.chdir('/content/drive/MyDrive/Q2/TCVD/PR/1/csv/')

!pwd

"""## Ampliar database
### Importar dades

#### Database original
"""

# import csv
import pandas as pd
temp = pd.read_csv("./el-prat-de-llobregat_2000_1.csv")

# funció per canvi de variable de variació (numerica a categorica)
def recodificar_cambio(valor):
    if valor > 0:
        return 'Creix'
    else:
        return 'Decreix'

# afegim variable de variació de la temperatura anualment
# variable any
temp['Date'] = pd.to_datetime(temp['Date'], format='%Y-%m')
temp['year'] = temp['Date'].dt.year
temp['Date'] = temp['Date'].dt.strftime('%Y-%-m')

# variable month
temp['Date'] = pd.to_datetime(temp['Date'], format='%Y-%m')
temp['month'] = temp['Date'].dt.month
temp['Date'] = temp['Date'].dt.strftime('%Y-%-m')

# ordenar per mes
temp = temp.sort_values(by=['month', 'year'])

# nova columna amb temperatura any anterior
temp['prev_year_temp'] = temp.groupby('month')['Avg Temperature'].shift(1)

# diferència percentual
temp['temp_annual_change'] = (temp['Avg Temperature'] - temp['prev_year_temp']) / temp['prev_year_temp'] * 100

# crear categòrica
temp['temp_annual_change_cat'] = temp['temp_annual_change'].apply(recodificar_cambio)

# tornar a ordenar per date
temp = temp.sort_values(by=['year', 'month'])

temp.tail(20)

"""#### Número de passatgers: webscraping
Dades de: https://www.barcelonaairport.net/passenger-statistics.shtml
"""

import requests
from bs4 import BeautifulSoup

url_hist= "https://www.barcelonaairport.net/passenger-statistics.shtml"
page = requests.get(url_hist)
print(page)
print(page.content)

soup = BeautifulSoup(page.content)
print(soup.prettify())

# Crear el dataframe. Pas1: Extreure les dades
# columna period
period = list()
for col1 in soup.find_all("div", attrs={"class":"col1"}):
    period.append(col1.get_text())

# columna passengers
passengers = list()
for col2 in soup.find_all("div", attrs={"class":"col2"}):
    passengers.append(col2.span.get_text())
passengers

# columna annual change
annual_change = list()
for col3 in soup.find_all("div", attrs={"class":"col3"}):
    annual_change.append(col3.span.get_text())

#Crear el dataframe. Pas2: convertir les lists en dataframe
import pandas as pd
passengers_df = pd.DataFrame(
    {'Date': period,
     'passengers': passengers,
     'annual_change': annual_change
    })

passengers_df.head(10)

"""#### Qualitat de l'aire: importar csv

Les dades s'han descarregat de:
https://www.aspb.cat/documents/informe-mensual-qualitat-aire-barcelona/

"""

# import xlsx
aire_df = pd.read_excel("./qualitataire_anuals.xlsx")
aire_df.rename(columns={'NO2': 'year'})

aire_df.head(10)

"""### Ajuntar els dataframes"""

# Netejar i preparar els dataframes, i arreglar els valors de les columnes d'unió
# dataframe passengers_df

# eliminar files innecessàries
values_to_drop = ['Period', '2001', '2002', '2003', '2004', '2005',
                  '2006', '2007', '2008', '2009', '2010',
                  '2011', '2012', '2013', '2014', '2015',
                  '2016', '2017', '2018 (to date)']

passengers_df= passengers_df[~passengers_df['Date'].isin(values_to_drop)]

# arreglar format data passengers
passengers_df['Date'] = pd.to_datetime(passengers_df['Date'], format='%B %Y')

passengers_df['Date'] = passengers_df['Date'].dt.strftime('%Y-%-m')

# arreglar format data temp
temp['Date'] = pd.to_datetime(temp['Date'], format='%Y-%m')
temp['Date'] = temp['Date'].dt.strftime('%Y-%-m')

#Ajuntar dataframes
data = pd.merge(temp, passengers_df, on = "Date", how="outer")

#Ajuntar dataframes amb aire
#data2 = pd.merge(data, aire_df, left_on="year", right_on="year",
#                 how="left", validate="m:1")

"""# Neteja i preparació de les dades
## Recodificació de les dades
"""

data.dtypes

# delete NA
df = data.iloc[24:]
df = df.iloc[:-74]
df = df.drop(columns=['Precipitation', 'Snowdepth'])

# variable passengers
df['passengers'] = df['passengers'].replace({',': ''}, regex=True)
df['passengers'] = df['passengers'].astype(int)

# variable annual_change a categorica
df['annual_change'] = df['annual_change'].replace({'%': ''}, regex=True)
df['annual_change'] = df['annual_change'].astype(float)

df['annual_change_cat'] = df['annual_change'].apply(recodificar_cambio)

# variable estació de l'any
def recodificar_est(valor):
    primavera = range(3,6) # març, abril, maig
    estiu = range(6,9) # juny, juliol, agost
    tardor = range(9,12) # setembre, octubre, novembre
    if valor in primavera:
        return 'Primavera'
    elif valor in estiu:
        return 'Estiu'
    elif valor in tardor:
        return 'Tardor'
    else:
        return 'Hivern'

df['estacio'] = df['month'].apply(recodificar_est)

# variables categòriques a int per a poder fer contrasts i models
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

df['temp_annual_change_cat_encoded'] = le.fit_transform(df['temp_annual_change_cat'])

df['annual_change_cat_encoded'] = le.fit_transform(df['annual_change_cat'])

df['estacio_encoded'] = le.fit_transform(df['estacio'])

df.tail(20)

df['annual_change_cat'] = df['annual_change_cat'].astype('category')
df['temp_annual_change'] = df['temp_annual_change'].astype('category')
df['estacio'] = df['estacio'].astype('category')

print(df.dtypes)

"""#Analisi de valors extrems

"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

numerical_columns = df.select_dtypes(include=[np.number])
delete=['temp_annual_change_cat_encoded', 'annual_change_cat_encoded', 'estacio_encoded']
numerical_columns=numerical_columns.drop(delete, axis=1)

num_numerical_columns = len(numerical_columns.columns)

plt.figure(figsize=(15, 15))
for i, column in enumerate(numerical_columns.columns, 1):
    plt.subplot(4, 3, i)
    sns.boxplot(data=numerical_columns[column])
    plt.title(f'Boxplot of {column}')

plt.tight_layout()
plt.show()

import numpy as np

def handle_outliers(df):
    numerical_columns = df.select_dtypes(include=[np.number])

    for column in numerical_columns.columns:
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])
        df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])

    return df

df_handled = handle_outliers(df)
df_handled.head(10)

numerical_columns = df_handled.select_dtypes(include=[np.number])
delete=['temp_annual_change_cat_encoded', 'annual_change_cat_encoded', 'estacio_encoded']
numerical_columns=numerical_columns.drop(delete, axis=1)

num_numerical_columns = len(numerical_columns.columns)

plt.figure(figsize=(15, 15))
for i, column in enumerate(numerical_columns.columns, 1):
    plt.subplot(4, 3, i)
    sns.boxplot(data=numerical_columns[column])
    plt.title(f'Boxplot of {column}')

plt.tight_layout()
plt.show()

"""# Entendre el nou dataframe"""

df_handled.describe()

df_handled.isnull().sum()

# petit estudi variables depenents
import matplotlib.pyplot as plt

#histograma passatgers
plt.hist(df_handled['passengers'], bins=30, color='skyblue', edgecolor='black')

plt.xlabel('Num passatgers')
plt.ylabel('Freqüència')
plt.title("Número de passatgers mensuals a l'aeroport de Barcelona (2002-2018)")

plt.show()

# passengers cada any (per mes)
s = plt.scatter(df_handled['year'], df_handled['passengers'],
            c =df_handled['month'])

month_labels = ['Gener', 'Febrer', 'Març', 'Abril', 'Maig', 'Juny',
                'Juliol', 'Agost', 'Setembre', 'Octubre', 'Novembre', 'Desembre']

plt.legend(s.legend_elements()[0], month_labels, bbox_to_anchor = (1 , 1))
plt.ylabel('Num passatgers')
plt.xlabel('Any')
plt.title("Evolució número de passatgers mensuals a l'aeroport de Barcelona entre el 2002-2018")

plt.show()

# passengers cada mes (per any)
s = plt.scatter(df_handled['month'], df_handled['passengers'],
            c =df_handled['year'])

plt.legend(*s.legend_elements(), bbox_to_anchor = (1 , 1))
plt.ylabel('Num passatgers')
plt.xlabel('Mes')
plt.title("Evolució número de passatgers mensuals a l'aeroport de Barcelona per mesos de l'any")

plt.show()

# passengers segons temperatura mitjana
s = plt.scatter(df_handled['Avg Temperature'], df_handled['passengers'],
                c = df_handled['year']) #canviar-ho a la categòrica

plt.legend(*s.legend_elements(), bbox_to_anchor = (1 , 1))
plt.ylabel('Num passatgers')
plt.xlabel('Avg Temperature')
plt.title("Número de passatgers mensuals a l'aeroport de Barcelona segons any")

plt.show()

"""## Metode supervisat"""

df_handled.head(10)

df_new.head(10)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

df_new = df_handled.drop(columns=['Date','annual_change_cat', 'annual_change_cat_encoded','temp_annual_change_cat','estacio'])

le = LabelEncoder()
df_new['annual_change_cat_encoded'] = le.fit_transform(df_handled['annual_change_cat'])

# División de datos
X = df_new
y = df_new['annual_change_cat_encoded']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Inicializar y entrenar el modelo
model = LogisticRegression()
model.fit(X_train, y_train)

# Predicción en el conjunto de prueba
y_pred = model.predict(X_test)

# Evaluación del modelo
print("Accuracy:", accuracy_score(y_test, y_pred))
conf_matrix = confusion_matrix(y_test, y_pred)
print("Matriz de Confusión:")
print(conf_matrix)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

inertia = []
k_range = range(1, 11)

le = LabelEncoder()
df_new['temp_annual_change_encoded'] = le.fit_transform(df_new['temp_annual_change'])

for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X)
    inertia.append(kmeans.inertia_)

plt.figure(figsize=(10, 6))
plt.plot(k_range, inertia, 'bo-')
plt.xlabel('Número de Clusters (k)')
plt.ylabel('Inercia')
plt.title('Método del Codo para K-Means')
plt.show()

from sklearn.cluster import KMeans

le = LabelEncoder()
df_new['temp_annual_change_encoded'] = le.fit_transform(df_new['temp_annual_change'])

# Aplicar el algoritmo K-Means
kmeans = KMeans(n_clusters=4, random_state=42)
df_new['cluster'] = kmeans.fit_predict(df_new)

# Visualización de los clusters
plt.figure(figsize=(10, 6))
sns.scatterplot(data=df_new, x='Avg Temperature', y='passengers', hue='cluster', palette='viridis')
plt.xlabel('Avg temperature')
plt.ylabel('passengers')
plt.title('Clusters basados en Temperatura')
plt.show()

# Imprimir los centros de los clusters
print("Centros de los clusters:")
print(kmeans.cluster_centers_)

le = LabelEncoder()
df_new['temp_annual_change_encoded'] = le.fit_transform(df_new['temp_annual_change'])

# Aplicar el algoritmo K-Means
kmeans = KMeans(n_clusters=4, random_state=42)
df_new['cluster'] = kmeans.fit_predict(df_new)

# Visualización de los clusters
plt.figure(figsize=(10, 6))
sns.scatterplot(data=df_new, x='temp_annual_change', y='annual_change', hue='cluster', palette='viridis')
plt.xlabel('temp_annual_change')
plt.ylabel('annual_change')
plt.title('Clusters basados en Temperatura')
plt.show()

# Imprimir los centros de los clusters
print("Centros de los clusters:")
print(kmeans.cluster_centers_)

"""## Contrast d'hipòtesis

### Contrastos de correlació
"""

# correlacions
import matplotlib.pyplot as plt
import numpy as np

corr = numerical_columns.corr()
corr.style.background_gradient(cmap='coolwarm')

"""Veiem que passangers té correlacions força altes amb year i les de temperatura."""

# test correlació entre num passatgers i temperatura
import statsmodels.api as sm
from scipy import stats

# primer, cal comprovar normalitat
# per passangers
shapiro = stats.shapiro(df_handled['passengers'])
print(shapiro)#p-valor <0.05, confirmem normalitat. comprovo amb qqplot:

fig, ax = plt.subplots(figsize=(7,4))
sm.qqplot(
    df_handled['passengers'],
    fit   = True,
    line  = 'q',
    alpha = 0.4,
    lw    = 2,
    ax    = ax
)
ax.set_title('Gràfic Q-Q de passengers', fontsize = 10,
             fontweight = "bold")
ax.tick_params(labelsize = 7)

# per avg temperature
shapiro = stats.shapiro(df_handled['Avg Temperature'])
print(shapiro) # es confirma normalitat

# després, comprovar homoscedasticitat

# test correlació (test cor de pearson)
from scipy.stats import pearsonr

pearsonr(df_handled['Avg Temperature'], df_handled['passengers'])

#pvalor <0.05, per tant, es confirma la correlació

"""### Test anova"""

# test anova per comprovar la relacio entre num passatgers i estació de l'any (categòrica)
# comprovació normalitat
# Q-Q plot per cada grup
from statsmodels.stats.anova import anova_lm
from statsmodels.formula.api import ols
#fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(9, 5))
#axes = axes.flat
groups = df_handled['estacio'].unique()
for group in groups:
    group_data = df_handled[df_handled['estacio'] == group]['passengers']
    sm.qqplot(group_data, line='s')
    plt.title(f'QQ plot per {group}')

plt.tight_layout()
plt.show()

# Shapiro-Wilk test per cada grup
for group in groups:
    group_data = df_handled[df_handled['estacio'] == group]['passengers']
    stat, p = stats.shapiro(group_data)
    print(f'Group {group} - Statistics={stat}, p={p}')

# Homocedasticitat
# comprovar variancies
# Check variance in each group
group_variances = df_handled.groupby("estacio")["passengers"].var()
print(group_variances)
# levene test
stat, p = stats.levene(
    df_handled[df_handled['estacio'] == "Primavera"]['passengers'],
    df_handled[df_handled['estacio'] == "Estiu"]['passengers'],
    df_handled[df_handled['estacio'] == "Tardor"]['passengers'],
    df_handled[df_handled['estacio'] == "Hivern"]['passengers']
)
print(f'Levene’s test - Statistics={stat}, p={p}')

# ANOVA
mod_anova = ols('passengers ~ C(estacio)', data=df_handled).fit()
anova_results = anova_lm(mod_anova)
print("ANOVA results:", anova_results)

# ALTERNATIVA no paramètrica: Kruskal
stat, p = stats.kruskal(
    df_handled[df_handled['estacio'] == "Primavera"]['passengers'],
    df_handled[df_handled['estacio'] == "Estiu"]['passengers'],
    df_handled[df_handled['estacio'] == "Tardor"]['passengers'],
    df_handled[df_handled['estacio'] == "Hivern"]['passengers']
)
print(f'Kruskal test - Statistics={stat}, p={p}')

# Mitjana i variància

for group in groups:
    group_data = df_handled[df_handled['estacio'] == group]['passengers']
    m = group_data.mean()
    s = group_data.var()
    print(f'Group {group} - Mitjana={m}, - Variancia={s}')

import seaborn as sns
fig, ax = plt.subplots(1, 1, figsize=(8, 4))
sns.boxplot(x=df_handled["estacio"], y=df_handled["passengers"], data=df_handled, ax=ax)
sns.swarmplot(x=df_handled["estacio"], y=df_handled["passengers"], data=df_handled, color='black', alpha = 0.5, ax=ax);

"""### Test chi quadrat"""

# chi quadrat per annual_change i temp_anual_change
# taula contingència
from scipy.stats import chi2_contingency
from tabulate import tabulate

contingency_table=pd.crosstab(index=df_handled['temp_annual_change_cat'], columns=df_handled['annual_change_cat'])

print(contingency_table)

# pova chi quadrat i p-valor
chi2, p_value, _, _ = chi2_contingency(contingency_table)

print("Chi-square test statistic:", chi2)
print("p-value:", p_value)


# no és significatiu

"""### Regressions"""

# Model lineal
import statsmodels.api as sm
import statsmodels.formula.api as smf

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

# condicions pel model
# no multicolinealitat: a matriu correlacions hem vist variables correlacionades,
# en treiem del model. agafarem: avg temp, year, estacio, wind, sea level pressure
df_modlin = df_handled[['passengers','Avg Temperature', 'year','estacio','Wind', 'Sea Level Pressure']]
df_modlin = df_modlin.rename(columns={'Avg Temperature': 'avg_temp', 'Sea Level Pressure': 'sea_lev_p'})

df_modlin.dtypes
# distribució normal de la variable resposta: ja l'hem comprovat
# homocedasticitat variabla resposta: comprovat
# valors atípics: gestionats

# model
model = ols('passengers ~ avg_temp + year + C(estacio) + Wind + sea_lev_p',
            data=df_modlin)

model_fit = model.fit()
print(model_fit.summary())

#no són significatives ni l'estacio, ni el vent. sí que sembla que hivern una mica

# model2
model2 = ols('passengers ~ avg_temp + year + sea_lev_p',
            data=df_modlin)

model2_fit = model2.fit()
print(model2_fit.summary())
# sembla també que no acaba de ser significativa per un 95% de confiança sea level pressure

# model3
model3 = ols('passengers ~ avg_temp + year',
            data=df_modlin)

model3_fit = model3.fit()
print(model3_fit.summary())

# Prediccions
# Divisió dades en train i test
df_modlin3 = df_handled[['passengers','Avg Temperature', 'year']]
df_modlin3 = df_modlin3.rename(columns={'Avg Temperature': 'avg_temp'})
X = df_modlin3.loc[:, df_modlin3.columns != 'passengers']
y = df_modlin3['passengers']

X_train, X_test, y_train, y_test = train_test_split(
                                        X.values,
                                        y.values,
                                        train_size   = 0.8,
                                        random_state = 42,
                                        shuffle      = True
                                    )

X_train = sm.add_constant(X_train, prepend=True)
model32 = sm.OLS(endog=y_train, exog=X_train,)
model32 = model32.fit()
print(model32.summary())

#MODEL3.2
# Prediccions amb iC 95%
prediccions = model32.get_prediction(exog = X_train).summary_frame(alpha=0.05)
prediccions['x'] = X_train[:, 1]
prediccions['y'] = y_train
prediccions = prediccions.sort_values('x')

# Gràfic model
fig, ax = plt.subplots(figsize=(6, 3.84))

ax.scatter(prediccions['x'], prediccions['y'], marker='o', color = "gray")
ax.plot(prediccions['x'], prediccions["mean"], linestyle='-', label="OLS")
ax.plot(prediccions['x'], prediccions["mean_ci_lower"], linestyle='--', color='red', label="95% CI")
ax.plot(prediccions['x'], prediccions["mean_ci_upper"], linestyle='--', color='red')
ax.fill_between(prediccions['x'], prediccions["mean_ci_lower"], prediccions["mean_ci_upper"], alpha=0.1)
ax.legend();